<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[解决无法证实的环境问题]]></title>
    <url>%2F2019%2F04%2F05%2F%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E8%AF%81%E5%AE%9E%E7%9A%84%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[起因OMS拉单服务发布生产后，预期的功能不起作用，能看到请求日志返回的HTTP头部信息类型不对，测试环境验证没有问题，发布包文件对比也没有问题 排查发现问题##首先定位是否网络问题 ###有外网访问权限root@oms_16_21 ~]# ping seller-open-api.gegejia.comPING seller-open-api.gegejia.com (101.37.227.56) 56(84) bytes of data.64 bytes from 101.37.227.56 (101.37.227.56): icmp_seq=1 ttl=94 time=6.28 ms ###正常返回数据[root@oms_16_21 ~]# curl -XPOST “http://seller-open-api.gegejia.com/order/findOrders&quot;{“code”:”P01”,”message”:”参数不合法”,”data”:”参数解析失败”} ###抓包查看请求发送情况1 开启监听tcpdump -i eth0 -w dump21.pcap2 发起请求服务调用第三方接口3 结束监听并分析没有域名seller-open-api.gegejia.com相关的数据包传输Curl排除环境问题中间的服务调用替换成Curl请求，由于sign值没有，数据包体内部数据不对，但请求可达并且可以监听到 ###排查程序报错进行拉单过程中请求到失败可能是验签失败将签名放到验证正常的测试环境，不能请求成功 解决思路设置验签默认值，在获取不到正常签名时将变量覆盖 结果程序问题需要代码修改后重新提交发布 总结故障出现不要急于下结论，排查问题从底层开始，验证从应用层开始]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tech linux tcpdump curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化]]></title>
    <url>%2F2019%2F03%2F29%2FMySQL%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MySQL优化参数优化 innodb_buffer_pool_size单实例性能设置为系统内存75%左右实例需求提高内存的命中率 90%以上即可实例标准化根据buffer_pool设置各种不同的规格，根据业务的形态选择规格注：源码中在innodb存储引擎层搜索srv_buf_pool_size(在srv0srv.c（定义） srv0start.c（实现）文件中) innodb_buffer_pool_instances将innodb_buffer_pool划分为不同的instance每个instance独立的LRU、FLUSH、FREE独立的mutex控制,instance内部也会有独立的锁大内存建议将instance划分出来，划分成多个来减少锁争用提高并发 注：在innodb存储引擎层搜索srv_buf_pool_instances（主要集中在的buf0buf.c文件） innodb_log_file_size innodb_log_buffer_size先写入innodb_log_bufferbuffer写满或事务提交，刷新数据大事务频繁，增加innodb_log_buffer_size大小注：在innodb存储引擎层搜索srv_log_buffer_size（主要在log0log.c文件中） innodb_thread_concurrency在innodb层的一个类似限流的功能innodb_thread_concurrency = 0，innodb内部自己控制并发数 并发压力非常大的时候kernel_mutex竞争 并发压力非常大的时候大量CPU上下文切换 设置后会对进入的SQL进行限制，增加处理延时，保证数据库不会hang住innodb_thread_concurrency设置为cpu的核心数，是不开超线程的核心数，很多推荐是两倍CPU数实际应用过程中两倍的在并发大的时候也会造成大量的堵塞，基本上不可服务，要缓解并发压力需要设置更小的值，比如8或16，这样数据库可以很快的恢复过来注：在innodb存储引擎层搜索srv_thread_concurrency（主要在srv0srv.c文件中）innodb_io_capacityinnodb每秒后台进程处理IO操作的数据页上限我们需要给innodb多少时间去赃页刷新，删除数据，purge这些IO的操作，如何去限制innodb_buffer_pool_size总的io处理能力上限innodb_buffer_pool_size=innodb_io_capacity X instance个数如果设备性能强劲可以设置尽量大一些，一般设置为75%innodb_buffer_pool_instances分割成多个内存块时，每个内存块的IO处理能力为：innodb_io_capacity/innodb_buffer_pool_instances 注：在innodb存储引擎层搜索srv_io_capacity（主要在srv0srv.c文件中） innodb_max_dirty_pages_pctinnodb从innodb buffer中刷新脏页的比例innodb_io_capacity是相对的值，需要设置另外的值来决定用多长时间做赃页的刷新，不超过设置的值大量刷新脏页，产生checkpoint，性能会较差，基本是跌底的状态脏页刷新innodb_max_dirty_pages_pct * innodb_io_capacity在IO设备比交强劲时innodb_io_capacity设置为1000，innodb_max_dirty_pages_pct设置成75%注： 在innodb存储引擎层搜索srv_max_buf_pool_modified_pct（主要在srv0srv.c文件中） innodb_flush_methodO_DSYNC：使用O_SYNC打开和刷新log文件，使用fsync()刷新数据文件。O_DIRECT：使用O_DIRECT打开数据文件，使用fsync()刷新日志文件和数据文件。 在raid设备上，为了避免数据被innodb_buffer和raid多次cache，而数据不落盘，设置为O_DIRECT方式。注：在innodb存储引擎层搜索srv_unix_file_flush_method（主要在log0log.c、os0file.c文件中） innodb_file_per_table不同的表空间可以灵活设置数据目录的地址每张表可以分布到一个ibd文件 去做软链 做软链的好处是不会产生IO竞争 并发上就可以提高，运维成本上更高，会有大量的文件分布到其他路径上避免共享表空间产生的IO竞争共享空间的buffer log，undo日志，系统表有顺序写也有随机写，这样在写的时候所有的性能会较差，如果表很多，单个共享空间的IBD文件较大，搜索和查找功能代价就会越高，因此建议拆分出来，每个表一个文件，搜索代价会降低 IO也会降低，作为默认配置在线上生产环境使用 innodb_flush_log_at_trx_commit非常核心的参数，每次提交事务的时候会进行磁盘IO的刷新，这样会减少数据的丢失0：不是实时的刷新磁盘，每秒将log buffer的内容写事务日志并且刷新到磁盘；1：每个事务提交后，将log_buffer的内容写事务日志并数据磁盘；2：每个事务提交，将log_buffer内容写事务日志，但不进行数据刷盘，有可能没调用系统的flush，在系统cache里面12345678910111213141516171819if (trx-&gt;flush_log_later) &#123; /* Do nothing yet */ trx-&gt;must_flush_log_later = TRUE;&#125; else if (flush_log_at_trx_commit == 0) &#123; /* Do nothing */&#125; else if (flush_log_at_trx_commit == 1) &#123; if (srv_unix_file_flush_method == SRV_UNIX_NOSYNC) &#123; /* 写到数据但是不会立即去刷盘 ，如果设置的不是O_DIRECT而是NOSYNC，效果和下面2是一样的*/ log_write_up_to(lsn, LOG_WAIT_ONE_GROUP, FALSE); &#125; else &#123; /* 写入log中并且立即刷盘 */ log_write_up_to(lsn, LOG_WAIT_ONE_GROUP, TRUE); &#125;&#125; else if (flush_log_at_trx_commit == 2) &#123; /* Write the log but do not flush it to disk */ log_write_up_to(lsn, LOG_WAIT_ONE_GROUP, FALSE);&#125; else &#123; ut_error;&#125; sync_binlog减少主备数据丢失，保证主备库的数据一致性指定刷新binlog的数目，非核心的系统，可以设置大一些1000活2000，对于核心系统尽量要保证主备库的一致性双1模式，即：innodb_flush_log_at_trx_commit = 1，sync_binlog = 1，这样主备的数据是一致的，不会丢失数据。 系统优化NUMA让CPU快速访问离CPU最近的内存，提高内存访问效率，性能会提高很多，跨单元的CPU访问内存会经过多个链路获取内存的分配，性能会下降innodb_buffer_pool尽量在内存里面，尽量避免跨单元的内存访问，如果是单机单实例，直接将NUMA直接关闭，不需要考虑这个问题，如果是单机多实例，可以考虑用NUMA做数据库资源的隔离NUMA下实例数必须是双数的，这样可以将两个实例分别部署到不同的CPU下，单数的不能使用NUMA，会出先有些实例饿死在os层numa关闭时，打开bios层的numa会影响性能，QPS会下降15-30%；在bios层面numa关闭是，无论os层面的numa是否打开，都不会影响性能。 malloc1、下载jemalloc源码包wget http://www.canonware.com/download/jemalloc/jemalloc-3.6.0.tar.bz2tar -xjf jemalloc-3.6.0.tar.bz22、编译安装cd jemalloc-3.6.0; ./configure;make &amp;make install3、配置MySQL[mysqld_safe]malloc-lib=$PATH/libjemalloc.so 网卡内存插法### 参考资料]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客使用心得]]></title>
    <url>%2F2019%2F03%2F29%2F%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[新建博客注册github注册一个gmail邮箱注册需要手机验证码验证，最好是FQ到gmail.com注册注册github帐号注册完帐号一定要进行邮箱压榨 新建和设置仓库新建github仓库域名name这段必须和用户名相同.github.io设置一个主题 安装和初始化安装windows客户端下载git的windows客户端 git客户端设置git bash的mintty界面右键选择options 最终的效果 配置SSH生成密钥生成密钥1ssh-keygen 上传公钥 克隆项目1git clone git@github.com:Nu11Point/nu11point.github.io.git 安装nodejs安装nodejs 官网下载安装淘宝cnpm 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装主题 12cnpm install hexo-cli -g 初始化 1234#新建一个目录作为站点根目录cd /d/blogroothexo initcnpm install 123456#安装部署工具cnpm install hexo-deployer-git --save#生成页面文件hexo g#开启本地预览站点，监听端口为4000hexo s 选择和配置主题选择多款主题默认的主题是配置站点和主题编辑修改根目录下的_config.yml文件 1234567891011121314title: Nu11Pointsubtitle: 学习笔记description: 学习笔记keywords:author: Victorlanguage: zh-CNtimezone: Asia/Shanghaifavicon: https://github.githubassets.com/favicon.ico# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://nu11point.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults: 生成和编辑内容新建文章1hexo new &quot;First new page&quot; 编辑tag和分类 发布博客生成页面1hexo g 本地测试1hexo s 浏览器打开http://localhost:4000 问题处理MD格式问题变换目录删除提交历史项目私有设置图片显示文章里面显示的图片必须放到文章名的目录下面才能正常显示]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库测试]]></title>
    <url>%2F2019%2F03%2F29%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[数据库测试TPC-C测试测试工具fio依赖libaiolibaio-devel编译安装 123456789101112./configure make``` 找到fio文件 ``` ./fio --filename=/root/img -direct=1 -iodepth 1 -rw=read -ioengine=psync \ -bs=16k -size=10G \ -numjobs=10 -runtime=10 \ -group_reporting -name=mytest \ --output-format=json 参数说明12345678910111213 --filename=/dev/mapper/vg_root-lv_root 这里选文件就是文件系统方式，如果选裸设备&lt;br&gt;就是裸设备方式，可能会对裸设备上的文件系统元数据损坏，访问该分区的文件时失败 -direct=1 取消buffer缓存 -iodepth 1 -rw=read 测试顺序读的IO -ioengine=psync -bs=16k 单词IO块大小为16K -size=200G 本次的测试文件大小为200g，以每次16k的io进行测试 -numjobs=10 本次的测试线程为10 -runtime=10 测试时间为10秒，如果不写则一直将200g文件分16k每次写完为止 -group_reporting 关于显示结果的，汇总每个进程的信息 -name=mytest --output-format=json 输出格式类型 测试工具 tpcc-mysqltar -xf tpcc-mysql-src.tgzvi /etc/profileexport PATH=/usr/local/mysql/bin:$PATHexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mysql/libcd tpcc-mysql/srcmaketpcc_load tpcc_start create database tpcc_test;mysql -uroot -p tpcc_test &lt; create_table.sqlmysql -uroot -p tpcc_test &lt; add_fkey_idx.sql./tpcc_load tpcc_test root “xxx” 1 123456TPCC Data Load Started... Loading Item . . . ...DATA LOADING COMPLETED SUCCESSFULLY. ./tpcc_start -h 127.0.0.1 -d tpcc_test -u root -w 1 -c 16 -r 1 -l 20 &gt;&gt; /tmp/result.txt-w warehouse数-c 线程数-r 1表示进行预热时间，如果不进行预热对数据影响较大，也不符合具体业务场景-l 进行时长 7122.000 TpmC每分钟的事务数是7122换算出来 测试工具 dbt2tar xf dbt2-0.40.tar.gzcd dbt2-0.40cpan Statistics::Descriptivecpan Test:Parsercpan Test::Reporter./configure –with-mysqlcd src/./datagen -w 1 -d /tmp/data1/ –mysqlcd ../scripts/mysql//build_db.sh -d dbt2 -f /tmp/data1 -h 127.0.0.1 -uroot如果遇到报错ERROR 1290编辑/etc/my.cnf 添加secure-file-priv = “/tmp/data1”导入完成开始压测./run_workload.sh -c 1 -d 10 -w 1 测试工具 sysbench安装tar xf sysbench.tar.gzcd sysbench./autogen.sh./configure –with-mysqlmakecd sysbench 准备数据./sysbench –test=tests/db/parallel_prepare.lua –max-time=100 –oltp-dist-type=uniform –max-requests=0 –mysql-user=root –mysql-table-engine=innodb –oltp-table-size=100 –oltp-tables-count=32 –oltp-range-size=90 –oltp-point-selects=1 –oltp-simple-ranges=1 –oltp-sum-ranges=1 –oltp-order-ranges=1 –oltp-distinet-ranges=1 –oltp-non-index-updates=10 –num-threads=20 –mysql-host=127.0.0.1 –mysql-port=3306 prepare测试./sysbench –test=tests/db/oltp.lua –max-time=100 –oltp-dist-type=uniform –max-requests=0 –mysql-user=root –mysql-table-engine=innodb –oltp-table-size=100 –oltp-tables-count=32 –oltp-range-size=90 –oltp-point-selects=1 –oltp-simple-ranges=1 –oltp-sum-ranges=1 –oltp-order-ranges=1 –oltp-distinet-ranges=1 –oltp-non-index-updates=10 –num-threads=20 –mysql-host=127.0.0.1 –mysql-port=3306 run分析结果12345678910111213141516171819202122232425OLTP test statistics: queries performed: read: 224450 //总select数量 write: 581813 //总update、insert、delete语句数量 other: 89626 //commit、unlock tables以及其mutex的数量 total: 895889 transactions: 44736 (447.21 per sec.) //通常需要关注的数字(TPS) read/write requests: 806263 (8059.91 per sec.) other operations: 89626 (895.96 per sec.) ignored errors: 154 (1.54 per sec.) //忽略的错误数 reconnects: 0 (0.00 per sec.) General statistics: total time: 100.0338s //即max-time指定的压测实际 total number of events: 44736 //总的事件数，一般与transactions相同 total time taken by event execution: 2000.2277s response time: min: 11.18ms avg: 44.71ms //95%的语句的平均响应时间 max: 617.58ms approx. 95 percentile: 81.95ms Threads fairness: events (avg/stddev): 2236.8000/15.83 execution time (avg/stddev): 100.0114/0.01]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL机器选型和系统规划]]></title>
    <url>%2F2019%2F03%2F29%2FMySQL%E6%9C%BA%E5%99%A8%E9%80%89%E5%9E%8B%E5%92%8C%E7%B3%BB%E7%BB%9F%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[机器选型业务评估业务需求响应时间response time RT 受综合因素影响的值 数据总量需要业务方提供一至两年的数据总量 （互联网行业也需要有一个大概的评估）每秒请求量业务初期的评估读写比每个接口可以评估出读写比，整个业务链路需要多少接口调用都是可以计算出来的重要程度如果是核心的系统响应时间应该是尽快，每秒请求量需要合理稳定会影响整个需求的评估 需求转化磁盘空间数据总量与磁盘有关，单个机器不能容纳实例的时候，采取两种方式，冷热数据分离和数据的拆分，纬度上有两个点历史数据以时间为准，拆分与业务相关从业务的角度进行拆分数据总量还会和备份恢复的时间有关联TPS/QPSTPS反映处理写请求的处理情况，QPS反映处理读请求的处理情况，转化成IO/内存的需求IOPS/CPU如果大多数操作能在内存中操作的话就能大大的降低磁盘IO和CPU响应时间的压力，oltp项目大量的写操作会导致cache的赃，会导致大量的IO操作，每秒请求量会影响IOPSMEMORY对于较重要业务系统，需要通过读写比来评估内存的大小，进而提高内存的命中率，减少响应时间，一般是90%操作都cache到内存，对响应时间要求不高的可以将配置降下来IO磁盘的IO处理能力强的话CPU的等待时间就相对较短，处理请求的能力就较高 需求 指标 响应时间 查询和操作ms级 数据总量 1年数据量大约1T 每秒请求量 每秒有1W次请求 读写比 4：1 重要程度 核心系统P1级故障 其他说明 数据具有时效性历史数据访问较少，一般会处理近15天内的数据，数据记录总长度大约1KB 11年数据量1T 1102410241024/(365243600)=34KB/S21w次请求读写比4：1 写2000次/s读8000次/s3记录长度1KB 每秒insert请求是34次，2000-34=1966次update delete4页大小16KB/S 2000X16=32M/S 8000X16=128M/S5热数据15天 15(1*1024/365)=42GB 为保证ms级访问内存需大于42GB HDD SSDRAID SATA HDDRAID SATA SSDPCI-E SSD 机型测试性能对比测试查看不同机型的性能瓶颈稳定性测试fio在初期测试的时候没有抖动，性能很好，如果测试时间非常长就会发生抖动，与擦除算法有关掉电保护测试拔电测试 三星SSD有这个问题内存异常测试恢复时间IO设备坏盘和rebuild测试rebuild时的IO是否满足需求防止单个机型缺货 成本评估设备成本单机处理能力提高程度和成本提高的程度进行对比运维成本降低机器数量，降低运维成本功耗成本SSD是HDD功耗的1/2 参考系统规划文件系统规划MySQL数据库的特点单数据目录MySQL数据库单个实例不能指定多个数据目录，写入数据会集中在单个分区里混合读写Btree是聚簇索引导致数据随机的访问，日志文件是顺序读写的，因此需要将数据文件和日志文件分开请求随机请求是随机的，访问的数据块也是随机的 文件系统划分系统分区HDD做系统盘保证系统的稳定数据分区划分时空间最大，性能要最好 SSD日志分区日志文件的写入压力与业务有关，大多数情况HDD是满足的IO调度日志分区和数据分区的测试，使用deadline的方式性能会更好cfq是基于时间片公平的调度策略 很多情况下会影响请求的响应时间使用deadline是相对较合理的 文件系统建议 /dev/sda1 /boot/dev/sda2 //dev/sda3 /home/dev/sda4 /tmp/dev/sdb1 /data/dev/sdc1 /log IO调度建议 临时生效数据盘echo deadline &gt; /sys/block/sdb/queue/scheduler日志盘echo deadline &gt; /sys/block/sdc/queue/scheduler开机生效vim /etc/rc.d/rc.local添加12345678for DISK in sdb sdc do # Select deadline scheduler first echo deadline &gt; /sys/block/$&#123;DISK&#125;/queue/scheduler # Now set deadline scheduler parametersecho 100 &gt; /sys/block/$&#123;DISK&#125;/queue/iosched/read_expireecho 4 &gt; /sys/block/$&#123;DISK&#125;/queue/iosched/writes_starved done 永久生效不区别磁盘 查看支持的调度cat /sys/block/sda/queue/schedulerdmesg | grep -i schedulerCentOS7grubby –update-kernel=ALL –args=”elevator=deadline”rebootCentOS6vim /boot/grub/menu.lstkernel … elevator=deadline rhgb quiet 数据库系统配置MySQL数据库顺序读写binlog日志顺序读写的，重要性仅次于数据文件，非常重要，主从同步，恢复都需要error日志顺序的slow日志顺序写入tmp日志建议使用tmpfs 性能要求较高事务日志是循环写入的 指定几个文件就是几个，大小可以自己控制，原生MySQL5.5以下版本要求总体小于4G percona和mariadb都取消了这个限制Doublewrite数据顺序读写，官方版本目录不能分离的，percona是有参数可以指定单独的分区空间 官方建议放在HDD单机多实例将顺序读写变成了随机读写MySQL引入DoubleWrite主要是为了避免BufferPool中的数据部分未写入到磁盘，而导致无法数据恢复的问题。正常情况下，DoubleWrite引入会影响5%~10%的性能损失。然而，在写入压力较大时，写入DoubleWrite就会与BufferPool的随机写入产生竞争，性能影响就会加剧目录划分建议将binlog，errorlog，slowlog存储在/log目录下将tmp目录指定到系统/tmp其他所有目录都指定到/data 案例场景binlog error slow日志文件存储在一个/log目录tmp目录为系统根目录/tmp其他所有目录指定为数据目录/data 参考]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[圈套]]></title>
    <url>%2F2019%2F03%2F25%2F%E5%9C%88%E5%A5%97%2F</url>
    <content type="text"><![CDATA[很多时候我们玩游戏，追剧看似非常休闲，非常令人放松。人开始慢慢成长，就慢慢把一些事实看明白。很多时候都在劝自己，不用活的那么明白。像别人一样多好，玩玩竞技游戏，追追最新的剧集，下班就窝在沙发里，干这些事情。但是越是这样，就越觉得自己消沉了，有一丝丝堕落的感觉。有一天我在面馆吃面条，看到老板10岁左右的女儿动作娴熟的在刷抖音之类视频APP。不觉的一惊，我眼里的她不就是别人眼里的我嘛。其实我这个人我并不在乎别人是怎么看我的。让我震惊的是，自己和面前这个小女孩一样当时并不清楚自己在做什么，想要什么。毫无疑问，我觉得我们是陷入了一种无法自行break的for循环里，这个函数并不是他所声明的那样的。详细的分析发现，各种各类游戏都存在着相同的模式，这可能也是他们生存之本，那就是盈利模式。随着游戏运营时间不断的递增，这些模式慢慢就变的繁琐和公式化。这款游戏就慢慢失去了原有的充满想象力的，我认为的最吸引人最核心的部分。在资本的压榨下，最终各种网络游戏变成了可怕的吸血终端。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>所思所想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL安装]]></title>
    <url>%2F2019%2F03%2F23%2FMySQL%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[源码编译必备工具包 工具 介绍 gcc g++ mysql5.6开始需要g++进行编译 cmake mysql5.5开始使用cmake2.8以上 bison 语法解析器需要用bison编译 ncourses-devel 用于终端操作的开发包 zlib mysql用zlib进行压缩 功能需要的包 工具 介绍 libxml 用于xml输入输出方式的支持 openssl 用于安全套接字方式通信 dtrace 用于诊断mysql问题 编译参数 参数 介绍 CMAKE_BUILD_TYPE 编译的版本类型：RelWithDebInfo和Debug，不同之处是RelWithDebInfo会进行优化。 CMAKE_INSTALL_PREFIX 指定make install安装的目标路径。 SYSCONFDIR 指定配置文件的默认路径。 MYSQL_DATADIR 指定data目录的默认路径。 WITH_DEBUG 指定是否有debugging信息，一般用于源码调试时，打开WITH_DEBUG，生产环境关闭。 ENABLED_PROFILING 指定是否可以使用show profile显示操作执行的详细信息。 DEFAULT_CHARSET 指定默认字符集，可以在启动的配置文件中指定。 DEFAULT_COLLATION 指定默认字符比较、排序的规则。 WITH_EXTRA_CHARSETS 指定其他可能使用的字符集。 WITH_SSL 指定SSL的类型，从5.6.6开始默认bundled类型，此外也可以指定SSL库的路径地址。 WITH_ZLIB 指定zlib的类型，用于压缩功能。 WITH_storage_STORAGE_ENGINE 指定编译支持的存储引擎，默认支持MyISAM，MERGE，MEMORY，CSV存储引擎。 ENABLED_LOCAL_INFILE 指定是否允许使用load data infile功能。 WITH_EMBEDDED_SERVER 指定是否编译libmysqld嵌入式库。 INSTALL_LAYOUT 指定安装的布局类型。 编译环境及命令CFLAGS=”-O3 -g -fno-exceptions -static-libgcc -fno-omit-frame-pointer -fno-strict-aliasing”CXX=g++CXXFLAGS=”-O3 -g -fno-exceptions -fno-rtti -static-libgcc -fno-omit-frame-pointer -fno-strict-aliasing”export CFLAGS CXX CXXFLAGScmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \ -DMYSQL_DATADIR=/data/mydata \ -DSYSCONFDIR=/etc \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_ARCHIVE_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_PREFSCHEMA_STORAGE_ENGINE=1 \ -DENABLED_LOCAL_INFILE=1 \ -DWITH_EMBEDDED_SERVER=1 \ -DINSTALL_LAYOUT=STANDALONE \ -DWITH_READLINE=1 \ -DWITH_SSL=bundled \ -DWITH_ZLIB=bundled \ -DWITH_LIBWRAP=0 \ -DMYSQL_UNIX_ADDR=/tmp/mysql.sock \ -DDEFAULT_CHARSET=utf8 \ -DDEFAULT_COLLATION=utf8_general_ci make -j &amp; make install 源码包下载前端页面拼写出来的下载地址MySQL5.5.37 功能定制规模化部署MySQL打rpm包mkdir rpmcd rpm 编写mysql.spec文件rpmbuild -bb mysql.spec 配置文件模版定义配置模版生成唯一的server_id每个实例的server_id必须不同，否则会造成循环复制，可以根据IP地址来生成 数据目录模版版本升级物理升级备份恢复升级大版本升级5.5升5.6是必须通过备份恢复进行升级小版本升级5.5.10到5.5.37只需要替换bin/mysqld和share/english/errmsg.sys最保险的方式是把bin，lib，share目录全部替换掉最后链接到数据库执行mysql_upgrade命令 问题小版本的替换和跨版本升级不是完全可靠的，mysql_upgrade会解决掉大多数的问题，如果mysql_upgrade本身有bug或者升级过程中数据错乱了都是不可逆转的 逻辑升级这种升级是最稳妥的 逻辑备份逻辑备份出来都是SQL96或者SQL99的语法，新版本都会兼容老版本的SQL语法 资源池管理资源管理需要有水位 实例管理单机多实例 cgroup 管控IO CPU innodb进程池管理内存 ##计算单个实例的资源利用率]]></content>
      <categories>
        <category>tech</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[习惯成自然，既是一种好的习惯，也就是我的意愿]]></title>
    <url>%2F2019%2F03%2F22%2F%E4%B9%A0%E6%83%AF%E6%88%90%E8%87%AA%E7%84%B6%EF%BC%8C%E6%97%A2%E6%98%AF%E4%B8%80%E7%A7%8D%E5%A5%BD%E7%9A%84%E4%B9%A0%E6%83%AF%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E6%88%91%E7%9A%84%E6%84%8F%E6%84%BF%2F</url>
    <content type="text"><![CDATA[今天我开始新的生活今天是搭建这个博客的第一天，重新整理这些年来的学到的和创造的。通过这种方式来温习过去的知识，并且把学习到的新知识分享出来。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>start</tag>
      </tags>
  </entry>
</search>
